{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c62be3b2-0b77-4ca5-a2f4-263df20eed9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Workspace/Formula1Project/includes/configuration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cc7b31c-c970-4a3e-97c5-dddd1ca552b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Workspace/Formula1Project/includes/common_functions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fd08852-4502-411d-a7cd-b2d6f662a62c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"p_file_date\", \"\")\n",
    "v_file_date = dbutils.widgets.get(\"p_file_date\")\n",
    "print(v_file_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35c8fb7d-f4a3-4db7-91bb-1be761cbe6a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# collecting all the disntict years for the new data we receive.\n",
    "race_years_list = spark.read.format(\"delta\").load(f\"{presentation_path}/race_results\", header=True).filter(f\"results_file_date = '{v_file_date}'\").distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4524a0c0-5bb1-431c-98e2-2dbafc4186b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "The idea here we will have races data for multiple years. So when a new race data for a particular year comes, we need to fetch all the races data for that year.This is because a driver's overall ranking depends on their performance in all races throughout the year. But here in our case our incremental data is having data of more than one race thats why we need to fetch race years from the new data arrived.\n",
    "\"\"\"\n",
    "from pyspark.sql.functions import col\n",
    "race_years = []\n",
    "for race_year in race_years_list:\n",
    "    race_years.append(race_year.race_year)\n",
    "race_results_df = spark.read.format(\"delta\").load(f\"{presentation_path}/race_results\", header=True).filter(col(\"race_year\").isin(race_years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a4a1df5-34ad-49fe-85f3-1c9ff06dc9ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, when, count, col\n",
    "\n",
    "results_grouped_df = race_results_df.groupBy(\n",
    "    \"race_year\", \"driver_name\", \"driver_nationality\",\n",
    ").agg(\n",
    "    sum(\"points\").alias(\"total_points\"), \n",
    "    count(when(col(\"position\") == 1, True)).alias(\"wins\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c944e3d1-1c53-409d-843f-2cc494ec657a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank, desc\n",
    "\n",
    "spec = Window.partitionBy(\"race_year\").orderBy(desc(\"total_points\"),desc(\"wins\"))\n",
    "display(results_grouped_df.withColumn(\"rank\", rank().over(spec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dbc196e-b177-43e4-af1c-f4a209cfa296",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merge_condition = \"tgt.race_year = src.race_year and tgt.driver_name = src.driver_name\"\n",
    "merge_data(results_grouped_df, presentation_path, \"f1_presentation\", \"driver_standings\", \"race_year\", merge_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7b5b1ed-52e8-4ec9-9bec-9d626cee75e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#results_grouped_df.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"f1_presentation.driver_standings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d987647d-b65d-44c6-83d9-410927147303",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#overwrite_partition(results_grouped_df,'race_year', 'f1_presentation','driver_standings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5a951b8-26b8-4062-8314-fb4823222900",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Driver_standings",
   "widgets": {
    "p_file_date": {
     "currentValue": "2021-04-18",
     "nuid": "a5a5185a-5469-414d-89a4-219095f40510",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "p_file_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "p_file_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
